**********
Quickstart
**********

Jobmon is a job-control system used for automating scientific workflows and running them on
distributed computing systems. It manages complex job and resource dependencies and manages
computing environment instability to execute dependably and assist in troubleshooting when
needed. It is developed and maintained by IHME's Scientific Computing team.

Jobmonâ€™s vision is to make it as easy as possible for everyone at IHME to run any kind of code
on any compute platform, reliably, and efficiently.

Install
#######

pip install
***********
To get started::

    pip install jobmon

conda install
*************
TODO: FILL IN THIS SECTION

plugins
*******
TODO: FILL IN THIS SECTION

.. note::
    If you get the error **"Could not find a version that satisfies the requirement jobmon (from version: )"** then create (or append) the following to your ``~/.pip/pip.conf``::

        [global]
        extra-index-url = https://artifactory.ihme.washington.edu/artifactory/api/pypi/pypi-shared/simple
        trusted-host = artifactory.ihme.washington.edu

.. note::

    Jobmon is intended to be used on the Slurm or UGE (Buster). At present, it has
    limited capabilities for executing Tasks locally on a single machine using
    either sequential execution or multiprocessing.

Jobmon Learning
###############
For a deeper dive in to Jobmon, check out some of our courses:
    1. `About Jobmon <https://hub.ihme.washington.edu/pages/viewpage.action?pageId=74531156>`_.
    2. `Learn Jobmon <https://hub.ihme.washington.edu/pages/viewpage.action?pageId=78062050>`_.
    3. `Jobmon Retry <https://hub.ihme.washington.edu/pages/viewpage.action?pageId=78062056>`_.
    4. `Jobmon Resume <https://hub.ihme.washington.edu/pages/viewpage.action?pageId=78062059>`_.

These courses are occasionally offered in-person. Check IHME Learn to see if there are any
upcoming trainings.

Getting Started
###############
The Jobmon controller script (i.e. the code defining the workflow) has to be
written in Python or R. The modeling code can be in Python, R, Stata, C++, or in fact any
language.

Users will primarily interact with Jobmon by creating a :term:`Workflow` and iteratively
adding :term:`Task` to it. Each Workflow is uniquely defined by its
:term:`WorkflowArgs` and the set of Tasks attached to it. A Workflow can only
be resumed if the WorkflowArgs and all Tasks added to it are shown to be
exact matches to the previous Workflow.

Create a Workflow
#################

A Workflow is a framework by which a user may define the relationship between
Tasks and define the relationship between multiple runs of the same set of Tasks.

A task is a single executable object in the workflow, a command that will be run.

A Workflow represents a set of Tasks which may depend on one another such
that if each relationship were drawn (Task A) -> (Task B) meaning that Task B
depends on Task A, it would form a `directed-acyclic graph (DAG) <https://en.wikipedia.org/wiki/Directed_acyclic_graph>`_.
A Workflow is further uniquely identified by a set of WorkflowArgs which are
required if the Workflow is to be resumable.

For more about the objects go to the :doc:`Workflow and Task Reference <api/jobmon.client>`
or :doc:`Executor Parameter Reference <api/jobmon.client.execution>`

Constructing a Workflow and adding a few Tasks is simple:

.. code-tabs::

    .. code-tab:: python
      :title: Python

      import os
      import getpass
      import uuid

      from jobmon.client.api import Tool, ExecutorParameters

      def workflow_template_example():
      """
      Instructions:

        The steps in this example are:
        1. Create a tool
        2. Create  workflow using the tool from step 1
        3. Create executor parameters to use with the tasks
        4. Create task templates using the tool from step 1
        5. Create tasks using the template from step 3
        6. Add created tasks to the workflow
        7. Run the workflow

      To actually run the provided example:
        with Jobmon installed in your conda environment from the root of the repo, run:
           $ python training_scripts/workflow_template_example.py
      """

      user = getpass.getuser()
      wf_uuid = uuid.uuid4()
      script_path = os.path.abspath(os.path.dirname(__file__))

      # Create a tool
      tool = Tool.create_tool(name="example tool")

      # Create a workflow, and set the executor
      workflow = tool.create_workflow(
        name = f"template_workflow_{wf_uuid}",
        description = "template_workflow")
      workflow.set_executor(
        executor_class='SGEExecutor',
        stderr = f"/ihme/scratch/users/{user}/{wf_uuid}",
        stdout = f"/ihme/scratch/users/{user}/{wf_uuid}",
        project = "proj_scicomp"  # specify your team's project
      )

      # Create task templates
      echo_template = tool.get_task_template(
        template_name='echo_template',
        command_template='echo {output}',
        task_args=['output'])

      python_template = tool.get_task_template(
        template_name='python_template',
        command_template='{python} {script_path} --args1 {val1} --args2 {val2}',
        task_args=['val1', 'val2'],
        op_args=['python', 'script_path'])

      # Create an executorparameters object for each task template
      echo_parameters = ExecutorParameters(
        num_cores=1,
        queue='all.q',
        max_runtime_seconds=10,
        m_mem_free='128M')

      python_parameters = ExecutorParameters(
        num_cores=2,
        queue='all.q',
        max_runtime_seconds=1000,
        m_mem_free='2G')


      # Create tasks
      task1 = echo_template.create_task(
        executor_parameters=echo_parameters,
        name='task1',
        output='task1'
      )

      task2 = echo_template.create_task(
        executor_parameters=echo_parameters,
        name='task2',
        upstream_tasks = [task1],
        output='task2'
      )

      task3 = python_template.create_task(
        executor_parameters=python_parameters,
        name='task3',
        upstream_tasks=[task2],
        python=sys.executable,
        script_path=os.path.join(script_path, 'test_scripts/test.py'),
        val1='val1',
        val2='val2'
      )

      # add task to workflow
      workflow.add_tasks([task1, task2, task3])

      # run workflow
      workflow.run()

    .. code-tab:: R
      :title: R

      Sys.setenv("RETICULATE_PYTHON"='/mnt/team/scicomp/envs/jobmon/bin/python')  # Set the Python interpreter path
      library(jobmonr)

      # Create a workflow
      username <- Sys.getenv("USER")
      script_path <- '/mnt/team/scicomp/training/test_scripts/test.py'  # Update with your repository installation

      # Templates are not supported in the R client, since there are no Jobmon 1.* R clients.
      # Create a tool

      my_tool <- tool(name='r_example_tool')

      # Bind a workflow to the tool
      wf <- workflow(tool,
        workflow_args=paste0('template_workflow_', Sys.Date()),
        name='template_workflow')

      # Set the executor
      wf <- set_executor(wf, executor_class='SGEExecutor')

      # Create an echoing task template
      echo_tt <- task_template(tool=my_tool,
        template_name='echo_templ',
        command_template='echo {}',
        task_args=list('echo_str'))


      # Create template to run our script
      script_tt <- task_template(tool=my_tool,
        template_name='test_templ',
        command_template=paste0(Sys.getenv("RETICULATE_PYTHON"), ' ', script_path, ' --args1 {val1} --args2 {val2}'),
        task_args=list('val1', 'val2'))


      # Define executor parameters for our tasks
      params <- executor_parameters(num_cores=1,
        m_mem_free="1G",
        queue='all.q',
        max_runtime_seconds=100)

      # Create two sleepy tasks
      task1 <- task(task_template=echo_tt,
        executor_parameters=copy(params),  # Copied to prevent parallel resource scaling
        name='echo_1',
        echo_str="task1")

      task2 <- task(task_template=echo_tt,
        executor_parameters=copy(params),
        name='echo_2',
        upstream_tasks=list(task1), # Depends on the previous task,
        echo_str="task2")

      # Add the test script task
      test_task <- task(task_template=tt,
        executor_parameters=copy(params),
        name='test_task',
        upstream_tasks=list(task2),
        val1="val1",
        val2="val2"
        )

      # Add tasks to the workflow
      wf <- add_tasks(wf, list(task1, task2, task3))

      # Run it
      wfr <- run(
        workflow=wf,
        resume=FALSE,
        seconds_until_timeout=7200)


.. note::
    Unique Workflows: If you know that your Workflow is to be used for a
    one-off project only, you may choose to use an anonymous Workflow, meaning
    you leave workflow_args blank. In this case, WorkflowArgs will default to
    a UUID which, as it is randomly generated, will be harder to remember and
    thus is not recommended for use cases outside of the one-off project. A workflow's
    uniqueness is based on it's command, upstreams and downstreams, and workflow_args.

Default Executor Parameters: ExecutorParameters are used to allocate resources for your tasks.
ExecutorParameters are specific to their given Executor. Jobmon current has the following
executors: SGE, Sequential, and Multiprocess.

Tasks, such as BashTask, PythonTask, etc. take many qsub-type arguments, that you can use to
specify ExecutorParameters. For the SGE executor you are able to specify number of
cores (num_cores), memory (m_mem_free), and runtime (max_runtime_seconds). By default, num_cores
used will be 1, mem_free will be 1G, and max attempts will be 3. Stderr, stdout, project,
and working_dir (if desired) are set at the Workflow level (see below).

Example of adding ExecutorParameters to a Task:

.. code-tabs::

    .. code-tab:: python
      :title: Python

        from jobmon.client.api import ExecutorParameters
        from jobmon.client.templates.bash_task import BashTask

        #Create ExecutorParameter
        executor_parameters_example = ExecutorParameters(
            m_mem_free = "1G",
            num_cores = 1,
            queue = "all.q",
            max_runtime_seconds = 60,
            executor_class="SGEExecutor"
        )

        #Create task and assign the ExecutorParameter to it
        task1 = BashTask(
            command = "echo task1",
            executor_parameters = executor_parameters_example
        )

    .. code-tab:: R
      :title: R

        library(jobmonr)
        executor_parameters_example <- executor_parameters(
            m_mem_free="1G",
            num_cores=1,
            queue='all.q',
            max_runtime_seconds=60,
            executor_class="SGEExecutor")


Additional Arguments: If you need to launch a Python, R, or Stata job, but
usually do so with a shellscript that sets environment variables before
running the full program, you can pass these environment variables to your
Jobmon Task, in the form of a dictionary. These will then be formatted and
prepended to the command, so that all environment variables will be set on
each node where the code executes. These additional arguments are called
context_args.

For example if you wanted to specify a host to run on, you would add context_args to a
task's ExecutorParameters

.. code-tabs::

    .. code-tab:: python
      :title: Python

        #Create ExecutorParameter
        executor_parameters_example = ExecutorParameters(
            m_mem_free = "1G",
            num_cores = 1,
            queue = "all.q",
            max_runtime_seconds = 60,
            executor_class="SGEExecutor",
            context_args={"sge_add_args": "-l hostname=<hostname>"}
        )

    .. code-tab:: R
        :title: R

        # Create Executor Parameter
        executor_parameters_example <- executor_parameters(
            m_mem_free = "1G",
            num_cores = 1,
            queue = "all.q",
            max_runtime_seconds = 60,
            executor_class="SGEExecutor",
            context_args=list("sge_add_args"="-l hostname=<hostname>")
        )

.. note::
    By default Workflows are set to time out if all of your tasks haven't
    completed after 10 hours (or 36000 seconds). If your Workflow times out
    before your tasks have finished running, those tasks will continue
    running, but you will need to restart your Workflow again. You can change
    this if your tasks combined run longer than 10 hours.

.. note::
    Errors with a return code of 199 indicate an issue occurring within Jobmon
    itself. Errors with a return code of 137 or 247 indicate resource errors.

Getting Additional Help
#######################
The Scientific Computing team is always available to answer your questions or to consult on
Jobmon.

To contact the team via Slack:
    - #jobmon-users to ask questions about Jobmon.

To set up a consultation:
    - Send a message in the #jobmon-users slack channel saying that you would like a
      consultation.
    - A Scientific Computing team member will reach out to you to schedule a consultation
      meeting.

To raise a Scientific Computing help desk request:
    - `SciComp Help Desk <https://help.ihme.washington.edu/servicedesk/customer/portal/16>`_.

When requesting help try to provide the team with as much information as you have about your
problem. *Please include your Workflow id, the Jobmon version that you're using, and any
TaskInstance error logs that you have.*
