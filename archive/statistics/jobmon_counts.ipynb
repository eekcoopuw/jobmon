{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def print_basic_stats( jobs_df, workflow_df, resumes_df ):\n",
    "    workflow_count = len(jobs_df['dag_id'].unique())\n",
    "    print( f\"Total number of workflows: {workflow_count}\")\n",
    "    \n",
    "    successful_job_count = len(jobs_df.loc[jobs_df['status']=='D'])\n",
    "    print( f\"Total number of successful jobs: {successful_job_count}\")\n",
    "    \n",
    "    earliest_status_date = workflow_df['status_date'].min()\n",
    "    print( f\"Earliest workflow status date: {earliest_status_date}\")\n",
    "    \n",
    "    last_status_date = workflow_df['status_date'].max()\n",
    "    print( f\"Last workflow status date: {last_status_date}\")\n",
    "    \n",
    "    max_job_count = workflow_df['number_of_jobs'].max()\n",
    "    print( f\"Max number of jobs in workflow: {max_job_count}\")\n",
    "    \n",
    "    done_df = workflow_df.loc[(workflow_df['status']=='D')]\n",
    "    median_job_count = done_df['number_of_jobs'].median()\n",
    "    print( f\"Median number of jobs in workflow: {median_job_count}\")\n",
    "    \n",
    "    retried_df = jobs_df.loc[(jobs_df['status']=='D') & (jobs_df['num_attempts'] > 1)]\n",
    "    immediate_df = jobs_df.loc[(jobs_df['status']=='D') & (jobs_df['num_attempts'] == 1)]\n",
    "    print( \"Immediate shape {i}, retry shape {r}\".format(i=immediate_df.shape, r=retried_df.shape))\n",
    "    # The following code not good due to bad data pull.\n",
    "    # workflowids and workflow_run_ids not unique across databases.\n",
    "    # Was not used in the paper\n",
    "#     good_df=resumes_df.loc[resumes_df['w_status']=='D']\n",
    "#     good_df['unique-key']=good_df['database'].astype(str) + \"_\" + good_df['w_id'].astype(str)\n",
    "\n",
    "def plot_workflow_sizes( workflow_df ):\n",
    "    \"\"\"Bucket the workflows by number of jobs, too inefficient for millions of jobs\"\"\"\n",
    "    job_counts = workflow_df['number_of_jobs']\n",
    "    plt.hist(job_counts, bins=100)\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title('Jobs per workflow')\n",
    "    \n",
    "def plot_retry_rates( jobs_df ):\n",
    "    \"\"\"Bucket number of retries\"\"\"\n",
    "    done_jobs_after_retry = jobs_df.loc[(jobs_df['status']=='D') & (jobs_df['num_attempts'] > 1)]\n",
    "    attempts = done_jobs_after_retry['num_attempts']\n",
    "    plt.hist(attempts, bins=30)\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title('#Attempts for Jobs that suceeded after the 1st attempt')\n",
    "    \n",
    "def plot_retry_rates_per_month( jobs_df ):\n",
    "    \"\"\"Plot %-rate of retries per month\"\"\"\n",
    "    jobs_df['year'] = jobs_df['date'].dt.year\n",
    "    jobs_df['month'] = jobs_df['date'].dt.month\n",
    "    jobs_df['month_index'] = (jobs_df['year']-2018)*12 + jobs_df['month'] - 4\n",
    "    retried_df = jobs_df.loc[(jobs_df['status']=='D') & (jobs_df['num_attempts'] > 1)]\n",
    "    g_retried_df = retried_df.groupby(['month_index']).count()[['num_attempts']]\n",
    "    immediate_df = jobs_df.loc[(jobs_df['status']=='D') & (jobs_df['num_attempts'] == 1)]\n",
    "    g_immediate_df = immediate_df.groupby(['month_index']).count()[['num_attempts']]\n",
    "    merge_df = g_immediate_df.join(g_retried_df, lsuffix='_immediate', rsuffix='_retried')\n",
    "    merge_df['rate'] = 100 * merge_df['num_attempts_retried'] / merge_df['num_attempts_immediate']   \n",
    "    rate_df = merge_df['rate']\n",
    "    \n",
    "    total_retries = retried_df.count()[['num_attempts']]\n",
    "    total_immediate = immediate_df.count()[['num_attempts']]\n",
    "    \n",
    "    r,_ = retried_df.shape\n",
    "    i,_= immediate_df.shape\n",
    "    percentage = (100*r)/i\n",
    "    print( f\"Overall Percentage retry rate {percentage}\")\n",
    "    \n",
    "    print('Calculations complete')\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(rate_df, color=\"black\")\n",
    "    plt.ylabel('%-Rate')\n",
    "    plt.xlabel('Month')\n",
    "    ax.set_xticks([x for x in range(12)])\n",
    "    x_ticks_labels = ['A','M', 'J', 'J','A','S','O','N','D','J','F','M']\n",
    "    ax.set_xticklabels(x_ticks_labels, rotation='vertical', fontsize=14)\n",
    "    plt.title('Retry %-rate per month from May 2018')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_retries_per_workflow( jobs_df ):\n",
    "    \"\"\"Which were the most unreliable workflow? Not useful, abandonded. Currently shows totals, not rate\n",
    "    For rate, copy the method used in the by-month graph\"\"\"\n",
    "    done_jobs = jobs_df.loc[(jobs_df['status']=='D') & (jobs_df['num_attempts'] > 1)]\n",
    "    done_by_workflow = done_jobs.groupby(['dag_id']).count()[['num_attempts']]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(done_by_workflow, color=\"black\")\n",
    "    plt.ylabel('%-Rate')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title('Retry Counts by Workflow')\n",
    "    plt.show()\n",
    "    \n",
    "def max_attempts_per_workflow( jobs_df ):\n",
    "    \"\"\"Bucket the workflows by number of jobs\"\"\"\n",
    "    done_jobs = jobs_df.loc[(jobs_df['status']=='D') ]\n",
    "    done_by_workflow = done_jobs.groupby(['dag_id']).max()\n",
    "    attempts_by_workflow = done_by_workflow['num_attempts']\n",
    "    plt.hist(attempts_by_workflow, bins=5)\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title('Max Attempts Counts by Workflow')\n",
    "    \n",
    "def clean_read( name, filepath, status_date_column_name ):\n",
    "    print( f\"Reading {name}\")\n",
    "    df = pd.read_hdf( filepath, key='counts', mode='r')\n",
    "    df['date'] = pd.to_datetime(df[status_date_column_name])\n",
    "    print( \"  {name} columns {c}\".format( name=name, c=list(df.columns) ))\n",
    "    print( \"  {name} shape {s}\".format(name=name, s=df.shape))\n",
    "    return df\n",
    "    \n",
    "def load():\n",
    "    root_path = '/ihme/homes/gphipps/results'\n",
    "    workflow_df = clean_read('workflow', f\"{root_path}/stats_workflows_all.h5\", 'status_date' )\n",
    "    jobs_df = clean_read('jobs', f\"{root_path}/stats_jobs_all.h5\", 'status_date' )\n",
    "    resumes_df = clean_read('resumes', f\"{root_path}/stats_resumes_all.h5\", 'wr_status_date' )\n",
    "    return workflow_df, jobs_df, resumes_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files once, as globals\n",
    "workflow_df, jobs_df, resumes_df = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_basic_stats( jobs_df, workflow_df, resumes_df  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Too inefficient and not needed\n",
    "#plot_workflow_sizes( workflow_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Too inefficient and not needed\n",
    "#plot_retry_rates( jobs_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_retry_rates_per_month( jobs_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not useful, left here as an example\n",
    "plot_retries_per_workflow( jobs_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_attempts_per_workflow( jobs_df )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
